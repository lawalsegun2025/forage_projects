{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "\n",
    "---\n",
    "\n",
    "## Web scraping and analysis\n",
    "\n",
    "This Jupyter notebook includes some code to get you started with web scraping. We will use a package called `BeautifulSoup` to collect the data from the web. Once you've collected your data and saved it into a local `.csv` file you should start with your analysis.\n",
    "\n",
    "### Scraping data from Skytrax\n",
    "\n",
    "If you visit [https://www.airlinequality.com](https://www.airlinequality.com) you can see that there is a lot of data there. For this task, we are only interested in reviews related to British Airways and the Airline itself.\n",
    "\n",
    "If you navigate to this link: [https://www.airlinequality.com/airline-reviews/british-airways](https://www.airlinequality.com/airline-reviews/british-airways) you will see this data. Now, we can use `Python` and `BeautifulSoup` to collect all the links to the reviews and then to collect the text data on each of the individual review links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting requests\n",
      "  Downloading requests-2.28.2-py3-none-any.whl (62 kB)\n",
      "     -------------------------------------- 62.8/62.8 kB 305.7 kB/s eta 0:00:00\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\segun lawal\\anaconda3\\envs\\zero_to_mastery_ml\\lib\\site-packages (from requests) (3.4)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.1.0-cp310-cp310-win_amd64.whl (97 kB)\n",
      "     -------------------------------------- 97.1/97.1 kB 504.8 kB/s eta 0:00:00\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\segun lawal\\anaconda3\\envs\\zero_to_mastery_ml\\lib\\site-packages (from requests) (2022.12.7)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
      "     ------------------------------------ 140.6/140.6 kB 642.4 kB/s eta 0:00:00\n",
      "Installing collected packages: urllib3, charset-normalizer, requests\n",
      "Successfully installed charset-normalizer-3.1.0 requests-2.28.2 urllib3-1.26.14\n"
     ]
    }
   ],
   "source": [
    "# # Install the requests module\n",
    "# !pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1\n",
      "   ---> 100 total reviews\n",
      "Scraping page 2\n",
      "   ---> 200 total reviews\n",
      "Scraping page 3\n",
      "   ---> 300 total reviews\n",
      "Scraping page 4\n",
      "   ---> 400 total reviews\n",
      "Scraping page 5\n",
      "   ---> 500 total reviews\n",
      "Scraping page 6\n",
      "   ---> 600 total reviews\n",
      "Scraping page 7\n",
      "   ---> 700 total reviews\n",
      "Scraping page 8\n",
      "   ---> 800 total reviews\n",
      "Scraping page 9\n",
      "   ---> 900 total reviews\n",
      "Scraping page 10\n",
      "   ---> 1000 total reviews\n",
      "Scraping page 11\n",
      "   ---> 1100 total reviews\n",
      "Scraping page 12\n",
      "   ---> 1200 total reviews\n",
      "Scraping page 13\n",
      "   ---> 1300 total reviews\n",
      "Scraping page 14\n",
      "   ---> 1400 total reviews\n",
      "Scraping page 15\n",
      "   ---> 1500 total reviews\n",
      "Scraping page 16\n",
      "   ---> 1600 total reviews\n",
      "Scraping page 17\n",
      "   ---> 1700 total reviews\n",
      "Scraping page 18\n",
      "   ---> 1800 total reviews\n",
      "Scraping page 19\n",
      "   ---> 1900 total reviews\n",
      "Scraping page 20\n",
      "   ---> 2000 total reviews\n",
      "Scraping page 21\n",
      "   ---> 2100 total reviews\n",
      "Scraping page 22\n",
      "   ---> 2200 total reviews\n",
      "Scraping page 23\n",
      "   ---> 2300 total reviews\n",
      "Scraping page 24\n",
      "   ---> 2400 total reviews\n",
      "Scraping page 25\n",
      "   ---> 2500 total reviews\n",
      "Scraping page 26\n",
      "   ---> 2600 total reviews\n",
      "Scraping page 27\n",
      "   ---> 2700 total reviews\n",
      "Scraping page 28\n",
      "   ---> 2800 total reviews\n",
      "Scraping page 29\n",
      "   ---> 2900 total reviews\n",
      "Scraping page 30\n",
      "   ---> 3000 total reviews\n"
     ]
    }
   ],
   "source": [
    "# base_url = \"https://www.airlinequality.com/airline-reviews/british-airways\"\n",
    "# pages = 30\n",
    "# page_size = 100\n",
    "\n",
    "# reviews = []\n",
    "\n",
    "# # for i in range(1, pages + 1):\n",
    "# for i in range(1, pages + 1):\n",
    "\n",
    "#     print(f\"Scraping page {i}\")\n",
    "\n",
    "#     # Create URL to collect links from paginated data\n",
    "#     url = f\"{base_url}/page/{i}/?sortby=post_date%3ADesc&pagesize={page_size}\"\n",
    "\n",
    "#     # Collect HTML data from this page\n",
    "#     response = requests.get(url)\n",
    "\n",
    "#     # Parse content\n",
    "#     content = response.content\n",
    "#     parsed_content = BeautifulSoup(content, 'html.parser')\n",
    "#     for para in parsed_content.find_all(\"div\", {\"class\": \"text_content\"}):\n",
    "#         reviews.append(para.get_text())\n",
    "    \n",
    "#     print(f\"   ---> {len(reviews)} total reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>✅ Trip Verified |  The incoming and outgoing f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>✅ Trip Verified |  Back in December my family ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>✅ Trip Verified |  As usual the flight is dela...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>✅ Trip Verified | A short BA euro trip and thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Not Verified |  We are flying Business class f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews\n",
       "0  ✅ Trip Verified |  The incoming and outgoing f...\n",
       "1  ✅ Trip Verified |  Back in December my family ...\n",
       "2  ✅ Trip Verified |  As usual the flight is dela...\n",
       "3  ✅ Trip Verified | A short BA euro trip and thi...\n",
       "4  Not Verified |  We are flying Business class f..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = pd.DataFrame()\n",
    "# df[\"reviews\"] = reviews\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"../data/BA_reviews.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! Now you have your dataset for this task! The loops above collected 1000 reviews by iterating through the paginated pages on the website. However, if you want to collect more data, try increasing the number of pages!\n",
    "\n",
    " The next thing that you should do is clean this data to remove any unnecessary text from each of the rows. For example, \"✅ Trip Verified\" can be removed from each row if it exists, as it's not relevant to what we want to investigate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis\n",
    "\n",
    "We have increased the dataset from 1000 reviews to 3000 reviews in order to improve the output of our analysis\n",
    "\n",
    "First let us list out our analysis work flow\n",
    "\n",
    "1. Data Loading\n",
    "2. Data Cleaning\n",
    "3. Word Cloud\n",
    "4. Topic Modeling\n",
    "5. Sentiment Analysis\n",
    "\n",
    "We have scrapped and loaded the data, now lets get to cleaning the data\n",
    "\n",
    "### 1. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/BA_reviews.csv\")\n",
    "df = df.drop(columns=[\"Unnamed: 0\"], errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>✅ Trip Verified |  The incoming and outgoing f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>✅ Trip Verified |  Back in December my family ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>✅ Trip Verified |  As usual the flight is dela...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>✅ Trip Verified | A short BA euro trip and thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Not Verified |  We are flying Business class f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews\n",
       "0  ✅ Trip Verified |  The incoming and outgoing f...\n",
       "1  ✅ Trip Verified |  Back in December my family ...\n",
       "2  ✅ Trip Verified |  As usual the flight is dela...\n",
       "3  ✅ Trip Verified | A short BA euro trip and thi...\n",
       "4  Not Verified |  We are flying Business class f..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import labraries for test data cleaning\n",
    "import pandas as pd \n",
    "import re \n",
    "import string \n",
    "import nltk\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "wn = nltk.WordNetLemmatizer()\n",
    "punct = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>cleaned_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>✅ Trip Verified |  Istanbul to London Heathrow. The plane itself was old, I found the  food choi...</td>\n",
       "      <td>trip verified istanbul to london heathrow the plane itself was old i found the food choices wer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2219</th>\n",
       "      <td>The British Airways outbound flight from London to Hong Kong was on a 3 year old A380. We sat ne...</td>\n",
       "      <td>the british airways outbound flight from london to hong kong was on a 3 year old a380 we sat nea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>✅ Trip Verified |  Hamburg to Abu Dhabi via London. Hamburg to Heathrow not even a free glass of...</td>\n",
       "      <td>trip verified hamburg to abu dhabi via london hamburg to heathrow not even a free glass of wate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>✅ Trip Verified |  Miami to London. My most recent BA experience was positive. I fly BA for work...</td>\n",
       "      <td>trip verified miami to london my most recent ba experience was positive i fly ba for work and l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>✅ Trip Verified |  Tenerife to Heathrow. Effectively a budget airline masquerading at premium ai...</td>\n",
       "      <td>trip verified tenerife to heathrow effectively a budget airline masquerading at premium airline...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>✅ Trip Verified | Having booked this flight a week before the BA strike and mistakingly thinking...</td>\n",
       "      <td>trip verified having booked this flight a week before the ba strike and mistakingly thinking th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>✅ Trip Verified |  San Francisco to London. A380 is a wonderful aeroplane. Movie selection was b...</td>\n",
       "      <td>trip verified san francisco to london a380 is a wonderful aeroplane movie selection was below a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2365</th>\n",
       "      <td>Heathrow to Las Vegas with British Airways, and a farcical flight to be honest. 2 hours into a 1...</td>\n",
       "      <td>heathrow to las vegas with british airways and a farcical flight to be honest 2 hours into a 10 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>✅ Trip Verified |  Frankfurt to London. BA staff watched while security went through partner's b...</td>\n",
       "      <td>trip verified frankfurt to london ba staff watched while security went through partners bag for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2655</th>\n",
       "      <td>Flight on time, nice crew on the plane, very comfortable seat and great food. Snacks and beverag...</td>\n",
       "      <td>flight on time nice crew on the plane very comfortable seat and great food snacks and beverages ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                  reviews  \\\n",
       "914   ✅ Trip Verified |  Istanbul to London Heathrow. The plane itself was old, I found the  food choi...   \n",
       "2219  The British Airways outbound flight from London to Hong Kong was on a 3 year old A380. We sat ne...   \n",
       "1012  ✅ Trip Verified |  Hamburg to Abu Dhabi via London. Hamburg to Heathrow not even a free glass of...   \n",
       "1025  ✅ Trip Verified |  Miami to London. My most recent BA experience was positive. I fly BA for work...   \n",
       "724   ✅ Trip Verified |  Tenerife to Heathrow. Effectively a budget airline masquerading at premium ai...   \n",
       "548   ✅ Trip Verified | Having booked this flight a week before the BA strike and mistakingly thinking...   \n",
       "484   ✅ Trip Verified |  San Francisco to London. A380 is a wonderful aeroplane. Movie selection was b...   \n",
       "2365  Heathrow to Las Vegas with British Airways, and a farcical flight to be honest. 2 hours into a 1...   \n",
       "625   ✅ Trip Verified |  Frankfurt to London. BA staff watched while security went through partner's b...   \n",
       "2655  Flight on time, nice crew on the plane, very comfortable seat and great food. Snacks and beverag...   \n",
       "\n",
       "                                                                                          cleaned_reviews  \n",
       "914    trip verified istanbul to london heathrow the plane itself was old i found the food choices wer...  \n",
       "2219  the british airways outbound flight from london to hong kong was on a 3 year old a380 we sat nea...  \n",
       "1012   trip verified hamburg to abu dhabi via london hamburg to heathrow not even a free glass of wate...  \n",
       "1025   trip verified miami to london my most recent ba experience was positive i fly ba for work and l...  \n",
       "724    trip verified tenerife to heathrow effectively a budget airline masquerading at premium airline...  \n",
       "548    trip verified having booked this flight a week before the ba strike and mistakingly thinking th...  \n",
       "484    trip verified san francisco to london a380 is a wonderful aeroplane movie selection was below a...  \n",
       "2365  heathrow to las vegas with british airways and a farcical flight to be honest 2 hours into a 10 ...  \n",
       "625    trip verified frankfurt to london ba staff watched while security went through partners bag for...  \n",
       "2655  flight on time nice crew on the plane very comfortable seat and great food snacks and beverages ...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This function cleans the data\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove punctuations \n",
    "    text = \"\".join([word.lower() for word in text if word not in punct])\n",
    "    \n",
    "    # Remove any other signs\n",
    "    text = \" \".join(re.split('\\W+', text))\n",
    "    \n",
    "    # remove trip, verified, review, unverified, not in the starting text\n",
    "    text = re.sub('\\^trip', \"\", text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "df[\"cleaned_reviews\"] = df[\"reviews\"]. apply(lambda x: clean_text(x))\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.sub()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "4f7924c4c56b083e0e50eadfe7ef592a7a8ef70df33a0047f82280e6be1afe15"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
